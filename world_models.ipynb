{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/izpc/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/izpc/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import math\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pong.pong import games_generator\n",
    "from pong.renderer import Renderer\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_game = games_generator(40, 40, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (frame, _) = next(get_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(frame[120])\n",
    "frame[120].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2ac8d31c234c7aa4cf69611ff39e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4000,), (4000, 256, 2), (4000, 256, 40, 40), (4000, 256))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directions = []\n",
    "controls = []\n",
    "frames = []\n",
    "done = []\n",
    "\n",
    "for _ in tqdm(range(4000)):\n",
    "    (d, c), (f, go) = next(get_game)\n",
    "    directions.append(d)\n",
    "    controls.append(c)\n",
    "    frames.append(f)\n",
    "    done.append(go)\n",
    "\n",
    "directions = np.array(directions)\n",
    "controls = np.array(controls)\n",
    "frames = np.array(frames)\n",
    "done = np.array(done)\n",
    "\n",
    "directions.shape, controls.shape, frames.shape, done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024000, 40, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_frames = frames.reshape((-1, 40, 40))\n",
    "only_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ef8dfd96f50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(only_frames[98548])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input((40, 40), name='input')\n",
    "e = i\n",
    "e = tf.keras.layers.Reshape((40, 40, 1))(e)\n",
    "e = tf.keras.layers.Conv2D(32, (4, 4), activation='relu', strides=2)(e)\n",
    "e = tf.keras.layers.Conv2D(64, (4, 4), activation='relu', strides=2)(e)\n",
    "e = tf.keras.layers.Conv2D(128, (4, 4), activation='relu', strides=2)(e)\n",
    "e = tf.keras.layers.Reshape((3 * 3 * 128,), name='flatten')(e)\n",
    "e = tf.keras.layers.Dense(32)(e)\n",
    "\n",
    "d = e\n",
    "d = tf.keras.layers.Dense(1024)(d)\n",
    "d = tf.keras.layers.Reshape((1, 1, 1024))(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(128, (4, 4), activation='relu', strides=2)(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(64, (5, 5), activation='relu', strides=1)(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(32, (5, 5), activation='relu', strides=2)(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(1, (4, 4), activation='relu', strides=2)(d)\n",
    "d = tf.keras.layers.Reshape((40, 40), name='frame')(d)\n",
    "\n",
    "net = tf.keras.Model(i, d)\n",
    "\n",
    "net.compile(\n",
    "    loss='mse',\n",
    "    optimizer='adam',\n",
    "    metrics=['mse', 'accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_input = tf.keras.layers.Input((32,))\n",
    "out = decode_input\n",
    "for l in net.layers[7:]:\n",
    "    out = l(out)\n",
    "    \n",
    "decoder = tf.keras.Model(decode_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 40, 40)]          0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 19, 19, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         131200    \n",
      "_________________________________________________________________\n",
      "flatten (Reshape)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              33792     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 128)         2097280   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 64)          204864    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 19, 19, 32)        51232     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 40, 40, 1)         513       \n",
      "_________________________________________________________________\n",
      "frame (Reshape)              (None, 40, 40)            0         \n",
      "=================================================================\n",
      "Total params: 2,589,153\n",
      "Trainable params: 2,589,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 563456/1024000 [===============>..............] - ETA: 50s - loss: 0.0031 - mean_squared_error: 0.0031 - acc: 0.4325"
     ]
    }
   ],
   "source": [
    "net.fit(\n",
    "    x=only_frames,\n",
    "    y=only_frames,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(only_frames[9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_f = net.predict(only_frames[9000].reshape(1, 40, 40)).reshape(40, 40)\n",
    "plt.imshow(pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_frames = []\n",
    "for f in tqdm(frames):\n",
    "    encoded_frames.append(encoder.predict(f))\n",
    "        \n",
    "encoded_frames = np.array(encoded_frames)\n",
    "encoded_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, stateful=False):\n",
    "        bs = 1 if stateful else None\n",
    "\n",
    "        init_dir = tf.keras.Input((1,), batch_size=bs)\n",
    "        user_input = tf.keras.Input((None, 2), batch_size=bs)\n",
    "\n",
    "        self.dir_hidden = tf.keras.layers.Dense(256)\n",
    "        self.dir_cell_state = tf.keras.layers.Dense(256)\n",
    "        self.lstm_input = tf.keras.layers.Dense(32)\n",
    "\n",
    "        self.lstm = tf.keras.layers.GRU(\n",
    "            256,\n",
    "            return_sequences=True,\n",
    "            stateful=stateful,\n",
    "            name='lstm'\n",
    "        )\n",
    "\n",
    "        self.done_logits = tf.keras.layers.Dense(1)\n",
    "        self.frame_logits1 = tf.keras.layers.Dense(128)\n",
    "        self.frame_logits2 = tf.keras.layers.Dense(32)\n",
    "        \n",
    "        dh = self.dir_hidden(init_dir)\n",
    "        dcs = self.dir_cell_state(init_dir)\n",
    "        li = self.lstm_input(user_input)\n",
    "        l = self.lstm(li, initial_state=[dh, dcs])\n",
    "        dl = self.done_logits(l)\n",
    "        fl = self.frame_logits2(self.frame_logits1(l))\n",
    "\n",
    "        self.net = tf.keras.Model([init_dir, user_input], [fl, dl])\n",
    "        self.net.compile(\n",
    "            loss='mse',\n",
    "            optimizer='adam',\n",
    "            metrics=['mse']\n",
    "        )\n",
    "\n",
    "    def init(self, direction):\n",
    "        self.direction = direction\n",
    "        self.first_time = True\n",
    "\n",
    "    def step(self, user_input):\n",
    "        user_input = np.array([[user_input]])\n",
    "        user_input = tf.convert_to_tensor(user_input, dtype=tf.float32)\n",
    "\n",
    "        direction = np.array([[self.direction]])\n",
    "        direction = tf.convert_to_tensor(direction, dtype=tf.float32)\n",
    "\n",
    "        li = self.lstm_input(user_input)\n",
    "\n",
    "        if self.first_time:q\n",
    "            self.first_time = False\n",
    "            dh = self.dir_hidden(direction)\n",
    "            dcs = self.dir_cell_state(direction)\n",
    "            l = self.lstm(li, initial_state=[dh, dcs])\n",
    "        else:\n",
    "            l = self.lstm(li)\n",
    "\n",
    "        dl = self.done_logits(l)\n",
    "        fl = self.frame_logits2(self.frame_logits1(l))\n",
    "\n",
    "        return fl[0].numpy(), dl[0].numpy()\n",
    "    \n",
    "    def copy_in_stateful_model(self):\n",
    "        stateful = Memory(stateful=True)\n",
    "        for nb, layer in enumerate(self.net.layers):\n",
    "            stateful.net.layers[nb].set_weights(layer.get_weights())\n",
    "        return stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()\n",
    "memory.net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.net.fit(\n",
    "    x=[directions.reshape(-1, 1), controls[:, 1:]],\n",
    "    y=[encoded_frames[:, :-1], np.expand_dims(done[:, :-1], -1)],\n",
    "    batch_size=128,\n",
    "    epochs=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 254\n",
    "game_id = 100\n",
    "plt.imshow(frames[game_id][idx])\n",
    "plt.show()\n",
    "\n",
    "pred_frames, pred_done = memory.net.predict([\n",
    "    directions.reshape(-1, 1)[game_id:game_id+1],\n",
    "    controls[:, 1:][game_id:game_id+1],\n",
    "    encoded_frames[:, 1:][game_id:game_id+1]\n",
    "])\n",
    "\n",
    "pred_frames[0][idx].reshape(1, -1).shape\n",
    "pred_image = decoder(pred_frames[0][idx].reshape(1, -1))[0]\n",
    "plt.imshow(pred_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo():\n",
    "    stateful = memory.copy_in_stateful_model()\n",
    "    \n",
    "    while True:\n",
    "        stateful.init(random.uniform(0, 2 * math.pi))\n",
    "\n",
    "        def step(user_input):\n",
    "            pref_frame, done = stateful.step(user_input)\n",
    "            return decoder.predict(pref_frame)[0], done\n",
    "\n",
    "        FPS = 60\n",
    "        Renderer.init_window(500, 500)\n",
    "\n",
    "        f = 0\n",
    "        while Renderer.can_render():\n",
    "            f += 1\n",
    "            sleep(1 / FPS)\n",
    "\n",
    "            controls = [\n",
    "                math.copysign(1, math.sin(f / 16)),\n",
    "                math.copysign(1, math.sin(f / 20 + 1.2))\n",
    "            ]\n",
    "            frame, done = step([1, 1])\n",
    "            done = done[0][0]\n",
    "            frame = np.concatenate((\n",
    "                frame,\n",
    "                np.array([[done] * frame.shape[0]] * 3)\n",
    "            ), axis=0)\n",
    "\n",
    "            if done > 0.8:\n",
    "                break\n",
    "\n",
    "            Renderer.show_frame(cm.bwr(1 - frame))\n",
    "\n",
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
