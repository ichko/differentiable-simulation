{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib as mpl\n",
    "\n",
    "from pong.pong import games_generator\n",
    "from pong.renderer import Renderer\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_game = games_generator(40, 40, 256, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (frame, _) = next(get_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEvCAYAAAAtufaDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAPGUlEQVR4nO3dbYyldXnH8e+vy7Io0MDiliwPKWppDTE6mHGr0RiLRShpAibG6AuzL0jWNpJoYhvRJi0mNdGmSvqisVkLsmmtSlEDMbSISEJMGnDVYdkFK4gYWVcWH4iQJgjr1RdzY2fXeTizcx68yveTnMx9/uc+c1+5M/Od8wSbqkKSuvqtWQ8gSRthxCS1ZsQktWbEJLVmxCS1ZsQktXbCRu6c5FLgH4BNwD9X1UdW2//EbKmTOHkjh5T0PPUkP/txVW07dv24I5ZkE/CPwMXAo8DXk9xSVfevdJ+TOJk/zJuO95CSnse+Ujd9f7n1jTyd3AE8VFUPV9UvgM8Cl2/g+0nSum0kYmcDP1hy/dFh7ShJdiXZm2TvMzy9gcNJ0q+b+Av7VbW7quaran4zWyZ9OEnPMxuJ2EHg3CXXzxnWJGlqNhKxrwPnJ3lxkhOBtwO3jGcsSRrNcb87WVXPJrkKuI3Fj1hcX1UHxjaZJI1gQ58Tq6pbgVvHNIskrZuf2JfUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPU2ob+BfAkjwBPAkeAZ6tqfhxDSeNw2w8XZj0CAJecNTfrEf5f21DEBn9UVT8ew/eRpHXz6aSk1jYasQK+nOQbSXYtt0OSXUn2Jtn7DE9v8HCSdLSNPp18fVUdTPI7wO1Jvl1Vdy3doap2A7sBfjtba4PHk6SjbOiRWFUdHL4eBr4I7BjHUJI0quOOWJKTk5z63DbwZmD/uAaTpFFs5OnkmcAXkzz3ff6tqv5zLFNJ0oiOO2JV9TDwyjHOIknr5kcsJLVmxCS1ZsQktWbEJLVmxCS1ZsQktWbEJLVmxCS1ZsQktWbEJLVmxCS1ZsQktWbEJLVmxCS1ZsQktWbEJLVmxCS1ZsQktWbEJLVmxCS1ZsQktWbEJLVmxCS1ZsQktWbEJLW25r8AnuR64E+Bw1X18mFtK/A54DzgEeBtVfWzyY0prd8lZ83NegRNwSiPxG4ALj1m7Wrgjqo6H7hjuC5JU7dmxKrqLuCnxyxfDuwZtvcAV4x5LkkayZpPJ1dwZlUdGrZ/BJy50o5JdgG7AE7ihcd5OEla3oZf2K+qAmqV23dX1XxVzW9my0YPJ0lHOd6IPZZkO8Dw9fD4RpKk0R1vxG4Bdg7bO4GbxzOOJK3PmhFL8hngv4A/SPJokiuBjwAXJ3kQ+OPhuiRN3Zov7FfVO1a46U1jnkWS1s1P7EtqzYhJas2ISWrNiElqzYhJas2ISWrNiElqzYhJas2ISWrNiElqzYhJas2ISWrNiElqzYhJas2ISWrNiElqzYhJas2ISWrNiElqzYhJas2ISWrNiElqzYhJas2ISWrNiElqbc2IJbk+yeEk+5esXZPkYJKF4XLZZMeUpOWN8kjsBuDSZdavraq54XLreMeSpNGsGbGqugv46RRmkaR128hrYlcl2Tc83Tx9pZ2S7EqyN8neZ3h6A4eTpF93vBH7BPBSYA44BHxspR2randVzVfV/Ga2HOfhJGl5xxWxqnqsqo5U1S+BTwI7xjuWJI3muCKWZPuSq28B9q+0ryRN0glr7ZDkM8AbgRcleRT4G+CNSeaAAh4B3jXBGSXN0G0/XJj1CABs2r78+poRq6p3LLN83QbnkaSx8BP7klozYpJaM2KSWjNiklozYpJaM2KSWjNiklozYpJaM2KSWjNiklozYpJaM2KSWjNiklozYpJaM2KSWjNiklozYpJaM2KSWjNiklozYpJaM2KSWjNiklozYpJaM2KSWjNiklpbM2JJzk1yZ5L7kxxI8p5hfWuS25M8OHw9ffLjStLRRnkk9izwvqq6AHgN8O4kFwBXA3dU1fnAHcN1SZqqNSNWVYeq6pvD9pPAA8DZwOXAnmG3PcAVkxpSklZywnp2TnIecCFwN3BmVR0abvoRcOYK99kF7AI4iRce75yStKyRX9hPcgrweeC9VfXzpbdVVQG13P2qandVzVfV/Ga2bGhYSTrWSBFLspnFgH26qr4wLD+WZPtw+3bg8GRGlKSVjfLuZIDrgAeq6uNLbroF2Dls7wRuHv94krS6UV4Tex3wTuC+JAvD2geBjwA3JrkS+D7wtrW+0e+/4n+47baFtXabqUvOmpv1CJLWYc2IVdXXgKxw85vGO44krY+f2JfUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPUmhGT1JoRk9SaEZPU2poRS3JukjuT3J/kQJL3DOvXJDmYZGG4XDb5cSXpaCeMsM+zwPuq6ptJTgW+keT24bZrq+rvJzeeJK1uzYhV1SHg0LD9ZJIHgLMnPZgkjWJdr4klOQ+4ELh7WLoqyb4k1yc5fYX77EqyN8nex39yZEPDStKxRo5YklOAzwPvraqfA58AXgrMsfhI7WPL3a+qdlfVfFXNbztj0xhGlqT/M1LEkmxmMWCfrqovAFTVY1V1pKp+CXwS2DG5MSVpeaO8OxngOuCBqvr4kvXtS3Z7C7B//ONJ0upGeXfydcA7gfuSLAxrHwTekWQOKOAR4F0TmVCSVjHKu5NfA7LMTbeOfxxJWh8/sS+pNSMmqTUjJqk1IyapNSMmqTUjJqk1IyapNSMmqTUjJqk1IyapNSMmqTUjJqk1IyapNSMmqTUjJqk1IyapNSMmqTUjJqk1IyapNSMmqTUjJqk1IyapNSMmqTUjJqk1IyaptTUjluSkJPckuTfJgSQfGtZfnOTuJA8l+VySEyc/riQdbZRHYk8DF1XVK4E54NIkrwE+ClxbVb8H/Ay4cnJjStLy1oxYLXpquLp5uBRwEXDTsL4HuGIiE0rSKkZ6TSzJpiQLwGHgduC7wBNV9eywy6PA2Svcd1eSvUn2Pv6TI+OYWZJ+ZaSIVdWRqpoDzgF2AC8b9QBVtbuq5qtqftsZm45zTEla3rrenayqJ4A7gdcCpyU5YbjpHODgmGeTpDWN8u7ktiSnDdsvAC4GHmAxZm8ddtsJ3DypISVpJSesvQvbgT1JNrEYvRur6ktJ7gc+m+RvgW8B101wTkla1poRq6p9wIXLrD/M4utjkjQzfmJfUmtGTFJrRkxSa0ZMUmtGTFJro3zEQtLz2CVnzc16hMFDy676SExSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa2tGLMlJSe5Jcm+SA0k+NKzfkOR7SRaGy2/K/4hb0vPIKP9QyNPARVX1VJLNwNeS/Mdw219W1U2TG0+SVrdmxKqqgKeGq5uHS01yKEka1UiviSXZlGQBOAzcXlV3Dzd9OMm+JNcm2bLCfXcl2Ztk7+M/OTKmsSVp0UgRq6ojVTUHnAPsSPJy4APAy4BXA1uB969w391VNV9V89vO2DSmsSVp0brenayqJ4A7gUur6lAtehr4FLBjEgNK0mpGeXdyW5LThu0XABcD306yfVgLcAWwf5KDStJyRnl3cjuwJ8kmFqN3Y1V9KclXk2wDAiwAfzbBOSVpWaO8O7kPuHCZ9YsmMpEkrYOf2JfUmhGT1JoRk9SaEZPUmhGT1NooH7EYm+/seyGXnOX/7ELS+PhITFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrRkxSa0ZMUmtGTFJrqarpHSx5HPj+cPVFwI+ndvCVOcfRnONoznG0Wc7xu1W17djFqUbsqAMne6tqfiYHdw7ncI7Wcyzl00lJrRkxSa3NMmK7Z3jspZzjaM5xNOc42m/KHL8ys9fEJGkcfDopqTUjJqm1mUQsyaVJ/jvJQ0munsUMwxyPJLkvyUKSvVM87vVJDifZv2Rta5Lbkzw4fD19RnNck+TgcE4Wklw2hTnOTXJnkvuTHEjynmF9qudklTmmek6SnJTkniT3DnN8aFh/cZK7h9+bzyU5cUZz3JDke0vOx9wk51hTVU31AmwCvgu8BDgRuBe4YNpzDLM8ArxoBsd9A/AqYP+Stb8Drh62rwY+OqM5rgH+YsrnYzvwqmH7VOA7wAXTPierzDHVcwIEOGXY3gzcDbwGuBF4+7D+T8Cfz2iOG4C3TvNnZLXLLB6J7QAeqqqHq+oXwGeBy2cwx8xU1V3AT49ZvhzYM2zvAa6Y0RxTV1WHquqbw/aTwAPA2Uz5nKwyx1TVoqeGq5uHSwEXATcN69M4HyvN8RtlFhE7G/jBkuuPMoMflEEBX07yjSS7ZjTDc86sqkPD9o+AM2c4y1VJ9g1PNyf+tHapJOcBF7L4V39m5+SYOWDK5yTJpiQLwGHgdhafvTxRVc8Ou0zl9+bYOarqufPx4eF8XJtky6TnWM3z/YX911fVq4A/Ad6d5A2zHggW/wIyu794nwBeCswBh4CPTevASU4BPg+8t6p+vvS2aZ6TZeaY+jmpqiNVNQecw+Kzl5dN+pijzJHk5cAHhnleDWwF3j+L2Z4zi4gdBM5dcv2cYW3qqurg8PUw8EUWf1hm5bEk2wGGr4dnMURVPTb84P4S+CRTOidJNrMYjk9X1ReG5amfk+XmmNU5GY79BHAn8FrgtCQnDDdN9fdmyRyXDk+7q6qeBj7FbH9vZhKxrwPnD++0nAi8Hbhl2kMkOTnJqc9tA28G9q9+r4m6Bdg5bO8Ebp7FEM9FY/AWpnBOkgS4Dnigqj6+5KapnpOV5pj2OUmyLclpw/YLgItZfH3uTuCtw27TOB/LzfHtJX9YwuLrcrP8vZn+u5PDOx2XsfjOz3eBv5rRDC9h8Z3Re4ED05wD+AyLT0ueYfG1jSuBM4A7gAeBrwBbZzTHvwD3AftYjMj2KczxehafKu4DFobLZdM+J6vMMdVzArwC+NZwvP3AXy/5mb0HeAj4d2DLjOb46nA+9gP/yvAO5qwu/mdHklp7vr+wL6k5IyapNSMmqTUjJqk1IyapNSMmqTUjJqm1/wXwQqzA0C5mhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(frame[120])\n",
    "frame[120].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.keras.layers.Input((40, 40), name='input')\n",
    "e = i\n",
    "e = tf.keras.layers.Reshape((40, 40, 1))(e)\n",
    "e = tf.keras.layers.Conv2D(32, (4, 4), activation='relu', strides=2)(e)\n",
    "e = tf.keras.layers.Conv2D(64, (4, 4), activation='relu', strides=2)(e)\n",
    "e = tf.keras.layers.Conv2D(128, (4, 4), activation='relu', strides=2)(e)\n",
    "e = tf.keras.layers.Reshape((3 * 3 * 128,), name='flatten')(e)\n",
    "e = tf.keras.layers.Dense(32)(e)\n",
    "\n",
    "d = e\n",
    "d = tf.keras.layers.Dense(1024)(d)\n",
    "d = tf.keras.layers.Reshape((1, 1, 1024))(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(128, (4, 4), activation='relu', strides=2)(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(64, (5, 5), activation='relu', strides=1)(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(32, (5, 5), activation='relu', strides=2)(d)\n",
    "d = tf.keras.layers.Conv2DTranspose(1, (4, 4), activation='relu', strides=2)(d)\n",
    "d = tf.keras.layers.Reshape((40, 40), name='frame')(d)\n",
    "\n",
    "ae = tf.keras.Model([i], [d])\n",
    "\n",
    "ae.compile(\n",
    "    loss='mse',\n",
    "    optimizer='adam',\n",
    "    metrics=['mse', 'accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(i, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_input = tf.keras.layers.Input((32,))\n",
    "out = decode_input\n",
    "for l in ae.layers[7:]:\n",
    "    out = l(out)\n",
    "    \n",
    "decoder = tf.keras.Model(decode_input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 40, 40)]          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 19, 19, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 128)         131200    \n",
      "_________________________________________________________________\n",
      "flatten (Reshape)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              33792     \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 4, 4, 128)         2097280   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 8, 8, 64)          204864    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 19, 19, 32)        51232     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 40, 40, 1)         513       \n",
      "_________________________________________________________________\n",
      "frame (Reshape)              (None, 40, 40)            0         \n",
      "=================================================================\n",
      "Total params: 2,589,153\n",
      "Trainable params: 2,589,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_generator():\n",
    "    while True:\n",
    "        _, (frames, _) = next(get_game)\n",
    "        for frame in frames:\n",
    "            yield frame, frame\n",
    "        \n",
    "make_dataset = lambda bs: tf.data.Dataset.from_generator(\n",
    "    frames_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    ").batch(bs).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/izpc/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:494: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "10000/10000 [==============================] - 71s 7ms/step - loss: 0.0222 - mean_squared_error: 0.0222 - acc: 0.3798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efb28033550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit_generator(\n",
    "    generator=make_dataset(bs=32),\n",
    "    steps_per_epoch=10_000,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efae0042b50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = next(frames_generator())[0]\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efb37bd3ed0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_f = ae.predict(frame.reshape(1, 40, 40)).reshape(40, 40)\n",
    "plt.imshow(pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, stateful=False):\n",
    "        bs = 1 if stateful else None\n",
    "\n",
    "        init_dir = tf.keras.Input((1,), batch_size=bs)\n",
    "        user_input = tf.keras.Input((None, 2), batch_size=bs)\n",
    "\n",
    "        self.dir_hidden = tf.keras.layers.Dense(256)\n",
    "        self.dir_cell_state = tf.keras.layers.Dense(256)\n",
    "        self.lstm_input = tf.keras.layers.Dense(32)\n",
    "\n",
    "        self.lstm = tf.keras.layers.GRU(\n",
    "            256,\n",
    "            return_sequences=True,\n",
    "            stateful=stateful,\n",
    "            name='lstm'\n",
    "        )\n",
    "\n",
    "        self.done_logits = tf.keras.layers.Dense(1)\n",
    "        self.frame_logits1 = tf.keras.layers.Dense(128)\n",
    "        self.frame_logits2 = tf.keras.layers.Dense(32)\n",
    "        \n",
    "        dh = self.dir_hidden(init_dir)\n",
    "        dcs = self.dir_cell_state(init_dir)\n",
    "        li = self.lstm_input(user_input)\n",
    "        l = self.lstm(li, initial_state=[dh])\n",
    "        dl = self.done_logits(l)\n",
    "        fl = self.frame_logits2(self.frame_logits1(l))\n",
    "\n",
    "        self.net = tf.keras.Model([init_dir, user_input], [fl, dl])\n",
    "        self.net.compile(\n",
    "            loss='mse',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy', 'mse']\n",
    "        )\n",
    "\n",
    "    def init(self, direction):\n",
    "        self.direction = direction\n",
    "        self.first_time = True\n",
    "\n",
    "    def step(self, user_input):\n",
    "        user_input = np.array([[user_input]])\n",
    "        user_input = tf.convert_to_tensor(user_input, dtype=tf.float32)\n",
    "\n",
    "        direction = np.array([[self.direction]])\n",
    "        direction = tf.convert_to_tensor(direction, dtype=tf.float32)\n",
    "\n",
    "        li = self.lstm_input(user_input)\n",
    "\n",
    "        if self.first_time:\n",
    "            self.first_time = False\n",
    "            dh = self.dir_hidden(direction)\n",
    "            dcs = self.dir_cell_state(direction)\n",
    "            l = self.lstm(li, initial_state=[dh])\n",
    "        else:\n",
    "            l = self.lstm(li)\n",
    "\n",
    "        dl = self.done_logits(l)\n",
    "        fl = self.frame_logits2(self.frame_logits1(l))\n",
    "\n",
    "        return fl[0].numpy(), dl[0].numpy()\n",
    "    \n",
    "    def copy_in_stateful_model(self):\n",
    "        stateful = Memory(stateful=True)\n",
    "        for nb, layer in enumerate(self.net.layers):\n",
    "            stateful.net.layers[nb].set_weights(layer.get_weights())\n",
    "        return stateful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 32)     96          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          512         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (GRU)                      (None, None, 256)    221952      dense_6[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, None, 128)    32896       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 32)     4128        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 1)      257         lstm[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 259,841\n",
      "Trainable params: 259,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "memory = Memory()\n",
    "memory.net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Weight and gradient histograms not supported for eagerexecution, setting `histogram_freq` to `0`.\n"
     ]
    }
   ],
   "source": [
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "memory.net.fit_generator(\n",
    "    x=[directions.reshape(-1, 1), controls[:, 1:]],\n",
    "    y=[encoded_frames[:, :-1], np.expand_dims(done[:, :-1], -1)],\n",
    "    validation_split=0.1,\n",
    "    batch_size=128,\n",
    "    epochs=1000,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 254\n",
    "game_id = 100\n",
    "plt.imshow(frames[game_id][idx])\n",
    "plt.show()\n",
    "\n",
    "pred_frames, pred_done = memory.net.predict([\n",
    "    directions.reshape(-1, 1)[game_id:game_id+1],\n",
    "    controls[:, 1:][game_id:game_id+1],\n",
    "    encoded_frames[:, 1:][game_id:game_id+1]\n",
    "])\n",
    "\n",
    "pred_image = decoder(pred_frames[0][idx].reshape(1, -1))[0]\n",
    "plt.imshow(pred_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_training_game():\n",
    "    Renderer.init_window(1000, 500)\n",
    "\n",
    "    for game_id in range(len(encoded_frames)):\n",
    "        latent_frames, _ = memory.net.predict([\n",
    "            directions.reshape(-1, 1)[game_id:game_id+1],\n",
    "            controls[:, 1:][game_id:game_id+1],\n",
    "            encoded_frames[:, 1:][game_id:game_id+1]\n",
    "        ])\n",
    "        pred_frames = decoder(latent_frames[0])\n",
    "        split_screens = np.concatenate(\n",
    "            (frames[game_id,1:], pred_frames), axis=2\n",
    "        )\n",
    "\n",
    "        n = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "        split_screens = n(split_screens)\n",
    "        split_screens = cm.bwr(1 - split_screens)\n",
    "\n",
    "        for frame in split_screens:\n",
    "            if not Renderer.can_render(): return\n",
    "            if Renderer.key_pressed('r'): break\n",
    "            Renderer.show_frame(frame)\n",
    "\n",
    "render_training_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_actual_game():\n",
    "    stateful = memory.copy_in_stateful_model()\n",
    "    Renderer.init_window(500, 500)\n",
    "    f = 0\n",
    "\n",
    "    while True:\n",
    "        stateful.init(random.uniform(0, 2 * math.pi))\n",
    "\n",
    "        def step(user_input):\n",
    "            pref_frame, done = stateful.step(user_input)\n",
    "            return decoder.predict(pref_frame)[0], done\n",
    "\n",
    "        while True:\n",
    "            f += 1\n",
    "\n",
    "            controls = [\n",
    "                math.copysign(1, math.sin(f / 16)),\n",
    "                math.copysign(1, math.sin(f / 20 + 1.2))\n",
    "            ]\n",
    "            frame, done = step(controls)\n",
    "            done = done[0][0]\n",
    "            frame = np.concatenate((\n",
    "                frame,\n",
    "                np.array([[done] * frame.shape[0]] * 3)\n",
    "            ), axis=0)\n",
    "            \n",
    "            if done > 0.8:\n",
    "                break\n",
    "\n",
    "            if not Renderer.can_render(): return\n",
    "            if Renderer.key_pressed('r'): break\n",
    "            Renderer.show_frame(cm.bwr(1 - frame))\n",
    "\n",
    "render_actual_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
